{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional network\n",
    "\n",
    "1. Stride: comment se deplace le kernel sur l'input (image, time series,...). Aussi definit comme la distance qui sépare 2 kernels consecutifs\n",
    "2. Padding: comment se comporte le filtre en bordure de l'input: \n",
    "    * no padding, le filtre s'arrete des qu'il rencontre le bord de l'image\n",
    "    * zero padding: des zeros sont concatené à l'image en bordure\n",
    "3. quand le stride est unitaire: astuce pour trouver la dimension de sortie: (input shape-kernel_size+1, nbre de kernel)\n",
    "     * no zero padding, units stride: $o= (i-k)+1$\n",
    "     * zero padding p, units stride: $o=(i+2p-k)+1$\n",
    "     * half/same padding: on veut output size =input size $o=i$: k impaire $k=2n+1$, $p=floor(k/2)=n$ alors $o=i+2p-(k-1)=i$\n",
    "     * full padding (effet de up-sampling)$p=k-1$\n",
    "4. Quand le stide s n'est plus unitaire:\n",
    "    * No zero padding, non unit stride: $o=floor((i-k)/s)+1$\n",
    "    * Zero padding, non units stride\n",
    "4. Accelerer le down-sampling: utiliser des Pooling layer (maxpooling,...)\n",
    "5. Le padding est souvent utiliser pour contrer l'effet du downsampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data structure and remark\n",
    "\n",
    "1. Image, multi dimensional time series: same structure: \n",
    "  * one dimesension for what matter (time axis, image dimension,...), \n",
    "  * one other called 'channel axis': red-blue-green for image, left and right channel)\n",
    "2. convolution = cross-correlation (from signal processing percptective)\n",
    "3. Operation pour faire la convolution: multiplication de l'output par une matrice de convolution qui est sparse (avec des zeros). On dit transpose convolution car on utlise la transposé de la matrice de convolution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.layers.merge import _Merge\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout\n",
    "from keras.layers import BatchNormalization, Activation, ZeroPadding2D, MaxPooling1D, GlobalAveragePooling1D, MaxPooling2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D, Conv1D,Conv2DTranspose\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import RMSprop\n",
    "from functools import partial\n",
    "\n",
    "import keras.backend as K\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1D Conv network\n",
    "\n",
    "1. 1st argument: nbre of kernel/filter\n",
    "2. 2nd argument: size of the kernel \n",
    "3. remark: stride=1 by default, no padding : le filtre se deplace de 1 en 1 partant du haut de la matrice vers le bas\n",
    "\n",
    "Dans cette example, avec 4 convolution 1D, on passe d'un input 2D de taille (80,3) à un output (44,160).\n",
    "\n",
    "Donc on fait du down-sampling\n",
    "\n",
    "https://blog.goodaudience.com/introduction-to-1d-convolutional-neural-networks-in-keras-for-time-sequences-3a7ff801a2cf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0927 11:10:39.198929  7508 deprecation_wrapper.py:119] From C:\\Users\\rochej\\AppData\\Local\\Continuum\\anaconda3\\envs\\ml_env\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0927 11:10:39.224859  7508 deprecation_wrapper.py:119] From C:\\Users\\rochej\\AppData\\Local\\Continuum\\anaconda3\\envs\\ml_env\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0927 11:10:39.233809  7508 deprecation_wrapper.py:119] From C:\\Users\\rochej\\AppData\\Local\\Continuum\\anaconda3\\envs\\ml_env\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0927 11:10:39.275760  7508 deprecation_wrapper.py:119] From C:\\Users\\rochej\\AppData\\Local\\Continuum\\anaconda3\\envs\\ml_env\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 71, 100)           3100      \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 60, 100)           120100    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 20, 100)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 11, 160)           160160    \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 2, 160)            256160    \n",
      "=================================================================\n",
      "Total params: 539,520\n",
      "Trainable params: 539,520\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "TIME_PERIODS=80\n",
    "num_sensors=3\n",
    "input_shape=(80,3)\n",
    "\n",
    "\n",
    "model_m = Sequential()\n",
    "#model_m.add(Reshape((TIME_PERIODS, num_sensors), input_shape=(input_shape,)))\n",
    "model_m.add(Conv1D(100, 10, activation='relu', input_shape=(TIME_PERIODS, num_sensors)))\n",
    "model_m.add(Conv1D(100, 12, activation='relu'))\n",
    "model_m.add(MaxPooling1D(3))\n",
    "model_m.add(Conv1D(160, 10, activation='relu'))\n",
    "model_m.add(Conv1D(160, 10, activation='relu'))\n",
    "print(model_m.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conditioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_99 (Conv1D)           (None, 20, 6)             186       \n",
      "_________________________________________________________________\n",
      "conv1d_100 (Conv1D)          (None, 10, 6)             186       \n",
      "_________________________________________________________________\n",
      "conv1d_101 (Conv1D)          (None, 5, 6)              186       \n",
      "_________________________________________________________________\n",
      "conv1d_102 (Conv1D)          (None, 3, 6)              186       \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 18)                0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 6)                 114       \n",
      "=================================================================\n",
      "Total params: 858\n",
      "Trainable params: 858\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "b=40\n",
    "k=6\n",
    "input_shape=(b,k)\n",
    "kernel_length=5\n",
    "\n",
    "\n",
    "model_m = Sequential()\n",
    "model_m.add(Conv1D(k, kernel_length, strides=2, activation='relu', input_shape=(b, k),padding='same'))\n",
    "model_m.add(Conv1D(k, kernel_length, strides=2, activation='relu',padding='same'))\n",
    "model_m.add(Conv1D(k, kernel_length, strides=2, activation='relu',padding='same'))\n",
    "model_m.add(Conv1D(k, kernel_length, strides=2, activation='relu',padding='same'))\n",
    "model_m.add(Flatten())\n",
    "model_m.add(Dense(k, activation='relu'))\n",
    "print(model_m.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulator\n",
    "\n",
    "1. Input shape=(4,k) result of the concatenation of:\n",
    "   * output du dense: (1,k)\n",
    "   * noise vector : (2,k)\n",
    "   * vector A: (1,k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Conv1DTranspose(input_tensor, filters, kernel_size, strides=2, padding='same'):\n",
    "    x = Lambda(lambda x: K.expand_dims(x, axis=2))(input_tensor)\n",
    "    x = Conv2DTranspose(filters=filters, kernel_size=(kernel_size, 1), strides=(strides, 1), padding=padding)(x)\n",
    "    x = Lambda(lambda x: K.squeeze(x, axis=2))(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_25 (Dense)             (None, 120)               3000      \n",
      "_________________________________________________________________\n",
      "reshape_22 (Reshape)         (None, 5, 24)             0         \n",
      "_________________________________________________________________\n",
      "reshape_23 (Reshape)         (None, 1, 5, 24)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_13 (Conv2DT (None, 1, 10, 12)         1452      \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_14 (Conv2DT (None, 1, 20, 6)          366       \n",
      "_________________________________________________________________\n",
      "reshape_24 (Reshape)         (None, 20, 6)             0         \n",
      "=================================================================\n",
      "Total params: 4,818\n",
      "Trainable params: 4,818\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "f=20\n",
    "print(k*f)\n",
    "\n",
    "model_s = Sequential()\n",
    "model_s.add(Dense(f*k, activation='relu',input_shape=(4*k,)))\n",
    "model_s.add(Reshape((int(f/4), int(4*k))))\n",
    "model_s.add(Reshape(( -1, int(f/4),int(4*k))))\n",
    "model_s.add(Conv2DTranspose(int(2*k),kernel_size=(1,5),strides=(1,2),padding='same'))\n",
    "model_s.add(Conv2DTranspose(int(k),kernel_size=(1,5),strides=(1,2),padding='same'))\n",
    "model_s.add(Reshape((int(f), int(k))))\n",
    "model_s.summary()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_94 (Conv1D)           (None, 30, 12)            372       \n",
      "_________________________________________________________________\n",
      "conv1d_95 (Conv1D)           (None, 15, 24)            1464      \n",
      "_________________________________________________________________\n",
      "conv1d_96 (Conv1D)           (None, 8, 48)             5808      \n",
      "_________________________________________________________________\n",
      "conv1d_97 (Conv1D)           (None, 4, 96)             23136     \n",
      "_________________________________________________________________\n",
      "conv1d_98 (Conv1D)           (None, 2, 192)            92352     \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 384)               0         \n",
      "=================================================================\n",
      "Total params: 123,132\n",
      "Trainable params: 123,132\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model_d = Sequential()\n",
    "model_d.add(Conv1D(2*k, kernel_length, strides=2, activation='relu', input_shape=(60, k),padding='same'))\n",
    "model_d.add(Conv1D(2*2*k, kernel_length, strides=2, activation='relu', input_shape=(60, k),padding='same'))\n",
    "model_d.add(Conv1D(2*2*2*k, kernel_length, strides=2, activation='relu', input_shape=(60, k),padding='same'))\n",
    "model_d.add(Conv1D(2*2*2*2*k, kernel_length, strides=2, activation='relu', input_shape=(60, k),padding='same'))\n",
    "model_d.add(Conv1D(2*2*2*2*2*k, kernel_length, strides=2, activation='relu', input_shape=(60, k),padding='same'))\n",
    "model_d.add(Flatten())\n",
    "print(model_d.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "192"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2**5*6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ici, on fait de la convolution sur le temps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2D Conv network\n",
    "\n",
    "1. remarque: input shape: toujours en 3D meme pour une matrice 2D (example, si input est une matrice (4,4), il faut rentrer (4,4,1)\n",
    "2. Par defaut, stride de (1,1): se deplace de 1 en 1 verticalement \n",
    "3. A l'inverse, stride de (2,2): meme effet que des pooling layer cad down-sampling\n",
    "On fait une reduction de dimension\n",
    "\n",
    "\n",
    "Operation interne à l'aide d'une matrice de convolution\n",
    "1. On construit la matrice de convolution à parir du kernel\n",
    "\n",
    "https://medium.com/activating-robotic-minds/up-sampling-with-transposed-convolution-9ae4f2df52d0\n",
    "\n",
    "https://www.pyimagesearch.com/2018/12/31/keras-conv2d-and-convolutional-layers/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_54 (Conv2D)           (None, 2, 2, 5)           10        \n",
      "=================================================================\n",
      "Total params: 10\n",
      "Trainable params: 10\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(5, kernel_size=(1,1), strides=(2, 2), activation='relu',input_shape=(4,4,1)))\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_55 (Conv2D)           (None, 18, 18, 100)       1000      \n",
      "_________________________________________________________________\n",
      "conv2d_56 (Conv2D)           (None, 8, 8, 200)         180200    \n",
      "_________________________________________________________________\n",
      "conv2d_57 (Conv2D)           (None, 6, 6, 200)         360200    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 3, 3, 200)         0         \n",
      "=================================================================\n",
      "Total params: 541,400\n",
      "Trainable params: 541,400\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "dim_image=(20,20)\n",
    "kernel_size=(3,3)\n",
    "\n",
    "data=np.ones((20,20))\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(100, kernel_size, strides=(1, 1), activation='relu',input_shape=(dim_image[0],dim_image[1],1)))\n",
    "model.add(Conv2D(200, kernel_size, strides=(2, 2), activation='relu'))\n",
    "model.add(Conv2D(200, kernel_size, strides=(1, 1), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transpose Conv\n",
    "Goal: upsampling as for DCGAN: take randomly sampled values to produce a full-size image\n",
    "1. stride refers to the manner in which outputs in the feature map are laid down\n",
    "2. on up-sample soit avec le stride, soit avec le kernel size\n",
    "3. La transpose convolution peut etre equivalent à une convolution en jouent sur le zero-padding (possible méthode mais moins efficace)\n",
    "\n",
    "Code tutorial:\n",
    "https://machinelearningmastery.com/upsampling-and-transpose-convolution-layers-for-generative-adversarial-networks/\n",
    "\n",
    "Introduction without code:\n",
    "https://medium.com/activating-robotic-minds/up-sampling-with-transposed-convolution-9ae4f2df52d0\n",
    "\n",
    "https://medium.com/apache-mxnet/transposed-convolutions-explained-with-ms-excel-52d13030c7e8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_transpose_8 (Conv2DTr (None, 4, 4, 5)           10        \n",
      "=================================================================\n",
      "Total params: 10\n",
      "Trainable params: 10\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2DTranspose(5, kernel_size=(1,1), strides=(2,2), input_shape=(2, 2, 1)))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_transpose_9 (Conv2DTr (None, 4, 4, 5)           50        \n",
      "=================================================================\n",
      "Total params: 50\n",
      "Trainable params: 50\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2DTranspose(5, kernel_size=(3,3), strides=(1,1), input_shape=(2, 2, 1)))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avec le padding='same', on force l'output de l'operation a avoir la même dimension que l'input\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_transpose_10 (Conv2DT (None, 4, 4, 1)           10        \n",
      "=================================================================\n",
      "Total params: 10\n",
      "Trainable params: 10\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2DTranspose(1, (3,3), strides=(2,2), padding='same', input_shape=(2, 2, 1)))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example d'un generateur construit avec Transpose convolution\n",
    "\n",
    "1. Goal: built an image of dimension: 10x10 \n",
    "2. Noise input: vector of 100 elements\n",
    "3. Avec un Dense layer: noise est transformé en 128 'images' de taille 5x5 qu'on va chercher à up-sampler en image de taille 10x10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 3200)              323200    \n",
      "_________________________________________________________________\n",
      "reshape_6 (Reshape)          (None, 5, 5, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_18 (Conv2DT (None, 10, 10, 1)         1153      \n",
      "=================================================================\n",
      "Total params: 324,353\n",
      "Trainable params: 324,353\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(128 * 5 * 5, input_dim=100))\n",
    "model.add(Reshape((5, 5, 128)))\n",
    "model.add(Conv2DTranspose(1, (3,3), strides=(2,2),padding='same'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 3200)              323200    \n",
      "_________________________________________________________________\n",
      "reshape_5 (Reshape)          (None, 5, 5, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_16 (Conv2DT (None, 11, 11, 1)         1153      \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_17 (Conv2DT (None, 22, 22, 1)         10        \n",
      "=================================================================\n",
      "Total params: 324,363\n",
      "Trainable params: 324,363\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras\n",
    "\n",
    "1. train_on_batch(x,y): \n",
    "    * Prend 2 argument x: training data et y: target value (labels)\n",
    "    * Runs a single gradient update on a single batch of data\n",
    "    * Return scalar training loss/ list of training loss (if the model has sevral outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 16)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noise=np.random.normal(0,1,(3,16)) #3 input de taille 16\n",
    "noise.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.10309774,  0.5624553 ],\n",
       "       [ 0.48000252, -1.9803181 ],\n",
       "       [-1.0735989 ,  0.12747216]], dtype=float32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model_simple\n",
    "model = Sequential()\n",
    "model.add(Dense(10,input_shape=(16,)))\n",
    "model.add(Dense(2))\n",
    "\n",
    "model.predict(noise)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_1, biases_1 = model.layers[0].get_weights()\n",
    "weights_2, biases_2 = model.layers[1].get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 10)\n",
      "(10, 2)\n"
     ]
    }
   ],
   "source": [
    "print(weights_1.shape)\n",
    "print(weights_2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170\n"
     ]
    }
   ],
   "source": [
    "#accès a la configuration de tout le reseau\n",
    "model.get_config()\n",
    "#acces au nombre de parametre optimisable dans la premiere courche= dimension de la  matrice + 10 biaises\n",
    "print(model.layers[0].count_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 2)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model_convolutional\n",
    "#k:nbre of filter\n",
    "k=10\n",
    "kernel_length=5\n",
    "b=40\n",
    "noise=np.random.normal(0,1,(3,b,k))# 3 input de taille b,k\n",
    "model_c = Sequential()\n",
    "model_c.add(Conv1D(k, kernel_length, strides=2, activation='relu', input_shape=(b, k),padding='same'))\n",
    "model_c.add(Flatten())\n",
    "model_c.add(Dense(2, activation='relu'))\n",
    "\n",
    "\n",
    "model_c.predict(noise).shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 10, 10)\n",
      "(10,)\n"
     ]
    }
   ],
   "source": [
    "weights_1, biases_1 = model_c.layers[0].get_weights()\n",
    "print(weights_1.shape)\n",
    "print(biases_1.shape) #egale au nombre de filtre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "w=model_c.layers[0].get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[16., 16., 16., 16., 16., 16., 16., 16., 16., 16.],\n",
       "       [16., 16., 16., 16., 16., 16., 16., 16., 16., 16.],\n",
       "       [16., 16., 16., 16., 16., 16., 16., 16., 16., 16.]], dtype=float32)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#eval tensor operation with numpy array\n",
    "real_noise=np.ones((3,10))*4\n",
    "tensor_noise=K.variable(real_noise)\n",
    "square_v=K.square(tensor_noise)\n",
    "K.eval(square_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4., 4., 4., 4., 4., 4., 4., 4., 4., 4.],\n",
       "       [4., 4., 4., 4., 4., 4., 4., 4., 4., 4.],\n",
       "       [4., 4., 4., 4., 4., 4., 4., 4., 4., 4.]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
